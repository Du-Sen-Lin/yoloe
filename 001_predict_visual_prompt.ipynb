{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fde70ed-4167-427d-8373-6ba2ee98b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927508c3-3aa3-4787-9e44-dbafc3d10cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af7b361d-1982-4282-9e6f-a8d901d0843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" \n",
    "\n",
    "# 设置 HTTP 和 HTTPS 代理\n",
    "os.environ[\"http_proxy\"] = \"***\"\n",
    "os.environ[\"https_proxy\"] = \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6fce82-a585-4ba4-9fe0-db0ad09761bf",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4aa39-76ce-42d1-8a56-f4e8d38cd92b",
   "metadata": {},
   "source": [
    "## visual prompt\n",
    "python predict_visual_prompt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c671ca14-4974-40fa-b056-f55ce49ce170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from PIL import Image\n",
    "import supervision as sv\n",
    "from ultralytics import YOLOE\n",
    "import numpy as np\n",
    "from ultralytics.models.yolo.yoloe.predict_vp import YOLOEVPSegPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "365129c5-1e29-44c9-9790-31b8b8fcc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63d615ae-d6ee-4883-a6b5-5b9892f97f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = \"./pretrain/yoloe-v8l-seg.pt\"  # yoloe-v8s-seg-det\n",
    "# checkpoint = \"./pretrain/yoloe-v8s-seg.pt\"\n",
    "device = \"cuda:0\"\n",
    "model = YOLOE(checkpoint)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62fef73-b978-43e0-a252-1fa7dd8f6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box1: [     221.52       405.8      344.98      857.54], box2: [        120         425         160         445]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "source_image_path = './ultralytics/assets/bus.jpg'\n",
    "target_image_path = './ultralytics/assets/zidane.jpg'\n",
    "\n",
    "output = \"/root/project/research/Yolo/yoloe/test_data_out/\"\n",
    "os.makedirs(output, exist_ok=True)\n",
    "\n",
    "source_image = Image.open(source_image_path).convert(\"RGB\")\n",
    "target_image = Image.open(target_image_path).convert(\"RGB\")\n",
    "\n",
    "# visuals = dict(\n",
    "#     bboxes=[\n",
    "#         np.array([[221.52, 405.8, 344.98, 857.54], [120, 425, 160, 445]]), \n",
    "#         np.array([[150, 200, 1150, 700]])\n",
    "#     ],\n",
    "#     cls=[\n",
    "#         np.array([0, 1]), \n",
    "#         np.array([0])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "visuals = dict(\n",
    "    bboxes=[\n",
    "        np.array([[221.52, 405.8, 344.98, 857.54], [120, 425, 160, 445]])\n",
    "    ],\n",
    "    cls=[\n",
    "        np.array([0, 1])\n",
    "    ]\n",
    ")\n",
    "\n",
    "box1 = visuals['bboxes'][0][0]\n",
    "box2 = visuals['bboxes'][0][1]\n",
    "print(f\"box1: {box1}, box2: {box2}\")\n",
    "\n",
    "# 转成整数坐标\n",
    "pt11 = tuple(box1[:2].astype(int))\n",
    "pt12 = tuple(box1[2:].astype(int))\n",
    "\n",
    "pt21 = tuple(box2[:2].astype(int))\n",
    "pt22 = tuple(box2[2:].astype(int))\n",
    "\n",
    "# 绘制矩形\n",
    "d_source_image = cv2.cvtColor(np.array(source_image), cv2.COLOR_RGB2BGR)\n",
    "d_source_image = cv2.rectangle(d_source_image, pt11, pt12, (255, 0, 0), 5)\n",
    "d_source_image = cv2.rectangle(d_source_image, pt21, pt22, (255, 0, 0), 5)\n",
    "d_source_image = cv2.cvtColor(d_source_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# ax.imshow(d_source_image, cmap=\"gray\") \n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# ax.imshow(target_image, cmap=\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a8dd83b-ad6d-49fc-88e6-39c8d2377b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bboxes': [array([[     221.52,       405.8,      344.98,      857.54],\n",
       "         [        120,         425,         160,         445]])],\n",
       " 'cls': [array([0, 1])]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c65877-92c0-486a-9eed-a6256d1e2193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 object0s, 2 object1s, 444.0ms\n",
      "Speed: 44.6ms preprocess, 444.0ms inference, 666.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/root/project/research/Yolo/ultralytics/runs/segment/predict23\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# results = model.predict([source_image, target_image], save=True, prompts=visuals, predictor=YOLOEVPSegPredictor)\n",
    "results = model.predict([source_image], save=True, prompts=visuals, predictor=YOLOEVPSegPredictor)\n",
    "# results = model.predict(source_image, save=False, prompts=visuals, predictor=YOLOEVPSegPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c4b2ee5-a668-43aa-9b94-71e315eb8919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotated_image: (810, 1080)\n",
      "base: ./ultralytics/assets, ext: bus.jpg\n",
      "output_name: /root/project/research/Yolo/yoloe/test_data_out/re_bus.jpg\n"
     ]
    }
   ],
   "source": [
    "detections = sv.Detections.from_ultralytics(results[0])\n",
    "# print(f\"detections: {detections}\")\n",
    "\n",
    "resolution_wh = source_image.size\n",
    "\n",
    "thickness = sv.calculate_optimal_line_thickness(resolution_wh=resolution_wh)\n",
    "text_scale = sv.calculate_optimal_text_scale(resolution_wh=resolution_wh)\n",
    "\n",
    "labels = [\n",
    "    f\"{class_name} {confidence:.2f}\"\n",
    "    for class_name, confidence in zip(detections[\"class_name\"], detections.confidence)\n",
    "]\n",
    "\n",
    "annotated_image = source_image.copy()\n",
    "\n",
    "annotated_image = sv.MaskAnnotator(\n",
    "    color_lookup=sv.ColorLookup.INDEX,\n",
    "    opacity=0.4\n",
    ").annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "annotated_image = sv.BoxAnnotator(\n",
    "    color_lookup=sv.ColorLookup.INDEX,\n",
    "    thickness=thickness\n",
    ").annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "annotated_image = sv.LabelAnnotator(\n",
    "    color_lookup=sv.ColorLookup.INDEX,\n",
    "    text_scale=text_scale,\n",
    "    smart_position=True\n",
    ").annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "print(f\"annotated_image: {annotated_image.size}\")\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# ax.imshow(annotated_image, cmap=\"gray\")\n",
    "\n",
    "base, ext = os.path.splitext(source_image_path)\n",
    "path, filename = os.path.split(source_image_path)\n",
    "print(f\"base: {path}, ext: {filename}\")\n",
    "output_name = os.path.join(output, \"re_\" + filename)\n",
    "print(f\"output_name: {output_name}\")\n",
    "annotated_image.save(output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391b328-eafc-4bb8-864f-4a19a1d6901e",
   "metadata": {},
   "source": [
    "## 一张图片的 visual prompt 去识别所有图片的对应目标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb67052-717f-4f72-904f-1c4505f2d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from PIL import Image\n",
    "import supervision as sv\n",
    "from ultralytics import YOLOE\n",
    "import numpy as np\n",
    "from ultralytics.models.yolo.yoloe.predict_vp import YOLOEVPSegPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7552626-00d0-4ffc-89d7-b8790f1c6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4381854-6720-4101-8826-861b3a52e171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = \"./pretrain/yoloe-v8l-seg.pt\"\n",
    "device = \"cuda:0\"\n",
    "model = YOLOE(checkpoint)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d6df89-48ee-4800-a19f-5ff1faad667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_source_image: (2048, 3072, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# source_image_path = './test_data/000000039769.jpg'\n",
    "source_image_path = \"/root/dataset/glass_data_20250317/images/train/Image_20250210134520105.bmp\"\n",
    "\n",
    "output = \"/root/project/research/Yolo/yoloe/test_data_out/\"\n",
    "os.makedirs(output, exist_ok=True)\n",
    "\n",
    "source_image = Image.open(source_image_path).convert(\"RGB\")\n",
    "\n",
    "# visuals = dict(\n",
    "#     bboxes=[\n",
    "#         np.array([[221.52, 405.8, 344.98, 857.54], [120, 425, 160, 445]]), \n",
    "#         np.array([[150, 200, 1150, 700]])\n",
    "#     ],\n",
    "#     cls=[\n",
    "#         np.array([0, 1]), \n",
    "#         np.array([0])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# visuals = dict(\n",
    "#     bboxes=[\n",
    "#         np.array([[221.52, 405.8, 344.98, 857.54], [120, 425, 160, 445]])\n",
    "#     ],\n",
    "#     cls=[\n",
    "#         np.array([0, 1])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# ----------- green leaf\n",
    "# visuals = dict(\n",
    "#     bboxes=[\n",
    "#         np.array([[662, 140, 1148, 532], [253, 609, 635, 788]])\n",
    "#     ],\n",
    "#     cls=[\n",
    "#         np.array([0, 0])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# -------- cats -----------\n",
    "# visuals = dict(\n",
    "#     bboxes=[\n",
    "#         np.array([[13, 56, 314, 470]])\n",
    "#     ],\n",
    "#     cls=[\n",
    "#         np.array([0])\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "visuals = dict(\n",
    "    bboxes=[\n",
    "        np.array([[900, 650, 1200, 820]])\n",
    "    ],\n",
    "    cls=[\n",
    "        np.array([0])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 绘制矩形\n",
    "d_source_image = cv2.cvtColor(np.array(source_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# 遍历 bbox 并画框\n",
    "for bbox in visuals[\"bboxes\"][0]:\n",
    "    pt1 = tuple(bbox[:2].astype(int))\n",
    "    pt2 = tuple(bbox[2:].astype(int))\n",
    "    d_source_image = cv2.rectangle(d_source_image, pt1, pt2, (255, 0, 0), 5)\n",
    "\n",
    "d_source_image = cv2.cvtColor(d_source_image, cv2.COLOR_BGR2RGB)\n",
    "print(f\"d_source_image: {d_source_image.shape}\")\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# ax.imshow(d_source_image, cmap=\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb5d1e2-1732-4a64-878b-62d1d763a034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 object0s, 42.4ms\n",
      "Speed: 5.1ms preprocess, 42.4ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# return_vpe=True 表示提取 VPE（Visual Prompt Embedding）用于后续使用。\n",
    "model.predict(source_image, prompts=visuals, predictor=YOLOEVPSegPredictor, return_vpe=True)\n",
    "# 相当于使用第一张图片的 visual prompt 去识别所有图片的对应目标\n",
    "# model.set_classes([\"person\", \"glasses\"], model.predictor.vpe)\n",
    "# model.set_classes([\"green leaf\"], model.predictor.vpe)\n",
    "model.set_classes([\"cat\"], model.predictor.vpe)\n",
    "model.predictor = None  # remove VPPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ba6b226-9761-4aa8-8799-5ec523a94584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 cats, 16.6ms\n",
      "Speed: 6.6ms preprocess, 16.6ms inference, 12.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# target_image_path = './ultralytics/assets/zidane.jpg'\n",
    "# target_image_path = './test_data/green_leaf.jpg'\n",
    "# target_image_path = './test_data/000000039769.jpg'\n",
    "target_image_path = \"/root/dataset/glass_data_20250317/images/train/Image_20250210134520105.bmp\"\n",
    "\n",
    "target_image = Image.open(target_image_path).convert(\"RGB\")\n",
    "\n",
    "# results = model.predict(target_image, save=True)\n",
    "results = model.predict(target_image, conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b42d046a-0458-401c-abd8-4c7d2a1d6374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detections: Detections(xyxy=array([[     928.08,      663.96,      1180.9,      806.42],\n",
      "       [     1428.9,      669.68,      1683.1,      811.23]], dtype=float32), mask=array([[[False, False, False, ..., False, False, False],\n",
      "        [False, False, False, ..., False, False, False],\n",
      "        [False, False, False, ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False, ..., False, False, False],\n",
      "        [False, False, False, ..., False, False, False],\n",
      "        [False, False, False, ..., False, False, False]],\n",
      "\n",
      "       [[False, False, False, ..., False, False, False],\n",
      "        [False, False, False, ..., False, False, False],\n",
      "        [False, False, False, ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False, ..., False, False, False],\n",
      "        [False, False, False, ..., False, False, False],\n",
      "        [False, False, False, ..., False, False, False]]]), confidence=array([    0.98826,     0.97257], dtype=float32), class_id=array([0, 0]), tracker_id=None, data={'class_name': array(['cat', 'cat'], dtype='<U3')}, metadata={})\n",
      "annotated_image: (3072, 2048)\n",
      "base: /root/dataset/glass_data_20250317/images/train, ext: Image_20250210134520105.bmp\n",
      "output_name: /root/project/research/Yolo/yoloe/test_data_out/re_Image_20250210134520105.bmp\n"
     ]
    }
   ],
   "source": [
    "detections = sv.Detections.from_ultralytics(results[0])\n",
    "print(f\"detections: {detections}\")\n",
    "\n",
    "resolution_wh = target_image.size\n",
    "\n",
    "thickness = sv.calculate_optimal_line_thickness(resolution_wh=resolution_wh)\n",
    "text_scale = sv.calculate_optimal_text_scale(resolution_wh=resolution_wh)\n",
    "\n",
    "labels = [\n",
    "    f\"{class_name} {confidence:.2f}\"\n",
    "    for class_name, confidence in zip(detections[\"class_name\"], detections.confidence)\n",
    "]\n",
    "\n",
    "annotated_image = target_image.copy()\n",
    "\n",
    "annotated_image = sv.MaskAnnotator(\n",
    "    color_lookup=sv.ColorLookup.INDEX,\n",
    "    opacity=0.4\n",
    ").annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "annotated_image = sv.BoxAnnotator(\n",
    "    color_lookup=sv.ColorLookup.INDEX,\n",
    "    thickness=thickness\n",
    ").annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "annotated_image = sv.LabelAnnotator(\n",
    "    color_lookup=sv.ColorLookup.INDEX,\n",
    "    text_scale=text_scale,\n",
    "    smart_position=True\n",
    ").annotate(scene=annotated_image, detections=detections, labels=labels)\n",
    "\n",
    "print(f\"annotated_image: {annotated_image.size}\")\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# ax.imshow(annotated_image, cmap=\"gray\")\n",
    "\n",
    "base, ext = os.path.splitext(target_image_path)\n",
    "path, filename = os.path.split(target_image_path)\n",
    "print(f\"base: {path}, ext: {filename}\")\n",
    "output_name = os.path.join(output, \"re_\" + filename)\n",
    "print(f\"output_name: {output_name}\")\n",
    "annotated_image.save(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "580125ec-4056-45bf-bfd4-f1d1fa49aabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask shape: (2, 640, 640)\n",
      "binary_mask: (640, 640)\n",
      "binary_mask: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# 所有目标的 mask\n",
    "masks = results[0].masks.data.cpu().numpy()  # shape: (num_objects, H, W)\n",
    "print(\"Mask shape:\", masks.shape)\n",
    "\n",
    "# 遍历每个目标的二值图\n",
    "for i, mask in enumerate(masks):\n",
    "    binary_mask = (mask > 0.5).astype(np.uint8) * 255  # 转为 uint8 的二值图\n",
    "    print(f\"binary_mask: {binary_mask.shape}\")\n",
    "    # fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    # ax.imshow(binary_mask, cmap=\"gray\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd6cf1-028f-4b19-95c2-703dee7d4cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
